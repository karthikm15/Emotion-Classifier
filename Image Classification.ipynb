{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/muxspace/facial_expressions.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries - Pandas, OS, Tensorflow, etc.\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil \n",
    "import os.path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import Sequential\n",
    "from keras.applications import VGG19 #For Transfer Learning\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "from keras.utils import to_categorical\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"facial_expressions/data/legend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user.id</th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868588k.jpg</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868585k.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868584k.jpg</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868582k.jpg</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dwdii</td>\n",
       "      <td>Aaron_Eckhart_0001.jpg</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13685</th>\n",
       "      <td>13685</td>\n",
       "      <td>jhamski</td>\n",
       "      <td>SharmilaTagore_80.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13686</th>\n",
       "      <td>13686</td>\n",
       "      <td>jhamski</td>\n",
       "      <td>SharmilaTagore_81.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13687</th>\n",
       "      <td>13687</td>\n",
       "      <td>jhamski</td>\n",
       "      <td>SharmilaTagore_82.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13688</th>\n",
       "      <td>13688</td>\n",
       "      <td>jhamski</td>\n",
       "      <td>SharmilaTagore_83.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13689</th>\n",
       "      <td>13689</td>\n",
       "      <td>jhamski</td>\n",
       "      <td>SharmilaTagore_9.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13690 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  user.id                            image    emotion\n",
       "0               0      628  facial-expressions_2868588k.jpg      anger\n",
       "1               1      628  facial-expressions_2868585k.jpg   surprise\n",
       "2               2      628  facial-expressions_2868584k.jpg    disgust\n",
       "3               3      628  facial-expressions_2868582k.jpg       fear\n",
       "4               4    dwdii           Aaron_Eckhart_0001.jpg    neutral\n",
       "...           ...      ...                              ...        ...\n",
       "13685       13685  jhamski            SharmilaTagore_80.jpg  happiness\n",
       "13686       13686  jhamski            SharmilaTagore_81.jpg  happiness\n",
       "13687       13687  jhamski            SharmilaTagore_82.jpg  happiness\n",
       "13688       13688  jhamski            SharmilaTagore_83.jpg  happiness\n",
       "13689       13689  jhamski             SharmilaTagore_9.jpg  happiness\n",
       "\n",
       "[13690 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizes different methods of representing the same emotion through case (e.g. \"ANGER\", \"Anger\", and \"anger\")\n",
    "df['emotion'] = [df['emotion'][i].lower() for i in df.index]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>facial-expressions_2868588k.jpg</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>facial-expressions_2868585k.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>facial-expressions_2868584k.jpg</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>facial-expressions_2868582k.jpg</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aaron_Eckhart_0001.jpg</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            image   emotion\n",
       "0           0  facial-expressions_2868588k.jpg     anger\n",
       "1           1  facial-expressions_2868585k.jpg  surprise\n",
       "2           2  facial-expressions_2868584k.jpg   disgust\n",
       "3           3  facial-expressions_2868582k.jpg      fear\n",
       "4           4           Aaron_Eckhart_0001.jpg   neutral"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at data and remove unnecessary columns\n",
    "del df['user.id']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13690"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'neutral',\n",
       " 'happiness',\n",
       " 'sadness',\n",
       " 'contempt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out unique emotions after normalization to use in our classification\n",
    "unique_emotions = list(df['emotion'].unique())\n",
    "unique_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1233</td>\n",
       "      <td>1233</td>\n",
       "      <td>Bill_Gates_0009.jpg</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3730</td>\n",
       "      <td>3730</td>\n",
       "      <td>George_Clooney_0005.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10557</td>\n",
       "      <td>10557</td>\n",
       "      <td>Rod_Bryden_0001.jpg</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6417</td>\n",
       "      <td>6417</td>\n",
       "      <td>John_Cornyn_0001.jpg</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3733</td>\n",
       "      <td>3733</td>\n",
       "      <td>George_Clooney_0008.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8209</th>\n",
       "      <td>11884</td>\n",
       "      <td>11884</td>\n",
       "      <td>Tom_Daschle_0022.jpg</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8210</th>\n",
       "      <td>2748</td>\n",
       "      <td>2748</td>\n",
       "      <td>Dennis_Hastert_0006.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>12869</td>\n",
       "      <td>12869</td>\n",
       "      <td>Dileep_7.jpg</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8212</th>\n",
       "      <td>5439</td>\n",
       "      <td>5439</td>\n",
       "      <td>Jacques_Chirac_0030.jpg</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8213</th>\n",
       "      <td>1635</td>\n",
       "      <td>1635</td>\n",
       "      <td>Carlos_Menem_0017.jpg</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8214 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Unnamed: 0                    image    emotion\n",
       "0      1233        1233      Bill_Gates_0009.jpg    neutral\n",
       "1      3730        3730  George_Clooney_0005.jpg  happiness\n",
       "2     10557       10557      Rod_Bryden_0001.jpg    neutral\n",
       "3      6417        6417     John_Cornyn_0001.jpg    neutral\n",
       "4      3733        3733  George_Clooney_0008.jpg  happiness\n",
       "...     ...         ...                      ...        ...\n",
       "8209  11884       11884     Tom_Daschle_0022.jpg    neutral\n",
       "8210   2748        2748  Dennis_Hastert_0006.jpg  happiness\n",
       "8211  12869       12869             Dileep_7.jpg    sadness\n",
       "8212   5439        5439  Jacques_Chirac_0030.jpg    neutral\n",
       "8213   1635        1635    Carlos_Menem_0017.jpg  happiness\n",
       "\n",
       "[8214 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1) \n",
    "train = df[0:int(len(df['image'])*0.6)]\n",
    "valid = df[int(len(df['image'])*0.6):]\n",
    "train = train.reset_index()\n",
    "valid = valid.reset_index()\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in train.index:\n",
    "#     if (index % 100 == 0):\n",
    "#         print(index)\n",
    "#     source = \"./facial_expressions/images/\"+train['image'][index]\n",
    "#     destination = './train/'+train['emotion'][index]+'/'+train['image'][index]\n",
    "#     if (os.path.exists(source) and not (os.path.exists(destination))):\n",
    "#         try:\n",
    "#             dest = shutil.move(source, destination)\n",
    "#         except:\n",
    "#             os.mkdir('train/'+train['emotion'][index])\n",
    "#             dest = shutil.move(source,destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in valid.index:\n",
    "#     if (index % 100 == 0):\n",
    "#         print(index)\n",
    "#     source = \"./facial_expressions/images/\"+valid['image'][index]\n",
    "#     destination = './valid/'+valid['emotion'][index]+'/'+valid['image'][index]\n",
    "    \n",
    "#     if (os.path.exists(source) and not (os.path.exists(destination))):\n",
    "#         try:\n",
    "#             dest = shutil.move(source, destination)\n",
    "#         except:\n",
    "#             os.mkdir('valid/'+valid['emotion'][index])\n",
    "#             dest = shutil.move(source,destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31515 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './train_resize',\n",
    "        target_size=(50, 50),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21850 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loading in testing data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        './valid_resize',\n",
    "        target_size=(50, 50),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# initialising sequential model and adding layers to it\n",
    "# cnn = tf.keras.models.Sequential()\n",
    "# cnn.add(tf.keras.layers.Conv2D(filters=48, kernel_size=3, activation='relu', input_shape=(3, 350, 350)))\n",
    "# cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# cnn.add(tf.keras.layers.Conv2D(filters=48, kernel_size=3, activation='relu'))\n",
    "# cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "# cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "# cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "# cnn.add(tf.keras.layers.Flatten())\n",
    "# cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "# cnn.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "# cnn.add(tf.keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Initializing sequential model that makes use of convolutional, pooling, and dense layers\n",
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=48, kernel_size=3, activation='relu', input_shape=(50, 50, 3), padding='same'))\n",
    "#cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.MaxPool2D((2,2), strides=(2,2), padding='same'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=48, kernel_size=3, activation='relu', padding = 'same'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = 'same'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding = 'same'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='same'))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto(\n",
    "#         device_count = {'GPU': 0}\n",
    "#     )\n",
    "# sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 50, 50, 48)        1344      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 25, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 48)        20784     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 32)        13856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 245,592\n",
      "Trainable params: 245,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1968/1970 [============================>.] - ETA: 0s - loss: 1.2935 - acc: 0.4717Epoch 1/12\n",
      "1970/1970 [==============================] - 203s 103ms/step - loss: 1.2934 - acc: 0.4718 - val_loss: 1.3624 - val_acc: 0.5011\n",
      "Epoch 2/12\n",
      "1969/1970 [============================>.] - ETA: 0s - loss: 0.8166 - acc: 0.6804Epoch 1/12\n",
      "1970/1970 [==============================] - 149s 75ms/step - loss: 0.8164 - acc: 0.6805 - val_loss: 1.6836 - val_acc: 0.5395\n",
      "Epoch 3/12\n",
      "1969/1970 [============================>.] - ETA: 0s - loss: 0.5651 - acc: 0.7833Epoch 1/12\n",
      "1970/1970 [==============================] - 413s 210ms/step - loss: 0.5649 - acc: 0.7833 - val_loss: 1.7841 - val_acc: 0.5578\n",
      "Epoch 4/12\n",
      "1969/1970 [============================>.] - ETA: 0s - loss: 0.4493 - acc: 0.8296Epoch 1/12\n",
      "1970/1970 [==============================] - 564s 286ms/step - loss: 0.4495 - acc: 0.8296 - val_loss: 2.1945 - val_acc: 0.5563\n",
      "Epoch 5/12\n",
      "1968/1970 [============================>.] - ETA: 0s - loss: 0.3788 - acc: 0.8569Epoch 1/12\n",
      "1970/1970 [==============================] - 451s 229ms/step - loss: 0.3791 - acc: 0.8568 - val_loss: 2.3186 - val_acc: 0.5590\n",
      "Epoch 6/12\n",
      "1969/1970 [============================>.] - ETA: 0s - loss: 0.3459 - acc: 0.8694Epoch 1/12\n",
      "1970/1970 [==============================] - 492s 250ms/step - loss: 0.3460 - acc: 0.8693 - val_loss: 2.6927 - val_acc: 0.5660\n",
      "Epoch 7/12\n",
      "1969/1970 [============================>.] - ETA: 0s - loss: 0.3159 - acc: 0.8801Epoch 1/12\n",
      "1970/1970 [==============================] - 572s 290ms/step - loss: 0.3158 - acc: 0.8802 - val_loss: 2.7344 - val_acc: 0.5714\n",
      "Epoch 8/12\n",
      "1969/1970 [============================>.] - ETA: 0s - loss: 0.2871 - acc: 0.8899Epoch 1/12\n",
      "1970/1970 [==============================] - 460s 233ms/step - loss: 0.2870 - acc: 0.8899 - val_loss: 2.7021 - val_acc: 0.5686\n",
      "Epoch 9/12\n",
      "1968/1970 [============================>.] - ETA: 0s - loss: 0.2727 - acc: 0.8958Epoch 1/12\n",
      "1970/1970 [==============================] - 481s 244ms/step - loss: 0.2725 - acc: 0.8958 - val_loss: 2.8306 - val_acc: 0.5652\n",
      "Epoch 10/12\n",
      "1969/1970 [============================>.] - ETA: 0s - loss: 0.2581 - acc: 0.9022Epoch 1/12\n",
      "1970/1970 [==============================] - 568s 288ms/step - loss: 0.2584 - acc: 0.9021 - val_loss: 3.0100 - val_acc: 0.5640\n",
      "Epoch 11/12\n",
      "1969/1970 [============================>.] - ETA: 0s - loss: 0.2500 - acc: 0.9047Epoch 1/12\n",
      "1970/1970 [==============================] - 505s 257ms/step - loss: 0.2499 - acc: 0.9047 - val_loss: 2.9297 - val_acc: 0.5753\n",
      "Epoch 12/12\n",
      "1968/1970 [============================>.] - ETA: 0s - loss: 0.2480 - acc: 0.9071Epoch 1/12\n",
      "1970/1970 [==============================] - 451s 229ms/step - loss: 0.2481 - acc: 0.9072 - val_loss: 2.9159 - val_acc: 0.5654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0357895668>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally compile and train the cnn\n",
    "cnn.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "cnn.fit(x=train_generator, validation_data=test_generator, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir model\n",
    "cnn.save('model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]  # will use this to convert prediction num to string value\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath)  # read in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)  # return the image with shaping that TF wants.\n",
    "\n",
    "prediction = cnn.predict([prepare('facial_expressions/test/52b.jpg')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('./model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger:14\n",
      "surprise:0\n",
      "disgust:1\n",
      "fear:0\n",
      "neutral:110\n",
      "happiness:100\n",
      "sadness:19\n",
      "contempt:19\n"
     ]
    }
   ],
   "source": [
    "unique_count = {'anger' : 0,\n",
    " 'surprise' : 0,\n",
    " 'disgust' : 0,\n",
    " 'fear' : 0,\n",
    " 'neutral' : 0,\n",
    " 'happiness' : 0,\n",
    " 'sadness' : 0,\n",
    " 'contempt' : 0}\n",
    "for test_file in os.listdir(\"./test_resize\"):\n",
    "    #print(test_file)\n",
    "    prediction = new_model.predict([prepare(\"./test_resize/\" + test_file)])\n",
    "    prediction_list = prediction.tolist()\n",
    "    prediction_list = prediction_list[0]\n",
    "    max_value = max(prediction_list)\n",
    "    maximum = -1\n",
    "    for index in prediction_list:\n",
    "        if (maximum < index):\n",
    "            maximum = index\n",
    "    unique_emotion = unique_emotions[prediction_list.index(maximum)]\n",
    "    \n",
    "    unique_count[unique_emotion] += 1\n",
    "\n",
    "for key in unique_count.keys():\n",
    "    print(key + \":\" + str(unique_count[key]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pictures = {'anger' : [],\n",
    " 'surprise' : [],\n",
    " 'disgust' : [],\n",
    " 'fear' : [],\n",
    " 'neutral' : [],\n",
    " 'happiness' : [],\n",
    " 'sadness' : [],\n",
    " 'contempt' : []}\n",
    "\n",
    "for test_file in os.listdir(\"./test_resize\"):\n",
    "    #print(test_file)\n",
    "    prediction = new_model.predict([prepare(\"./test_resize/\" + test_file)])\n",
    "    prediction_list = prediction.tolist()\n",
    "    prediction_list = prediction_list[0]\n",
    "    max_value = max(prediction_list)\n",
    "    maximum = -1\n",
    "    for index in prediction_list:\n",
    "        if (maximum < index):\n",
    "            maximum = index\n",
    "    unique_emotion = unique_emotions[prediction_list.index(maximum)]\n",
    "    \n",
    "    unique_pictures[unique_emotion].append(\"./test_resize/\" + test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f031bf40978>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cv2.imread(unique_pictures['sadness'][8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "val = cv2.imread(unique_pictures['anger'][0])\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
